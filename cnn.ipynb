{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "if tf.test.gpu_device_name():\n",
    "    print(f\"GPU used: {tf.test.gpu_device_name()}\")\n",
    "else:\n",
    "    print(f\"GPU not used\")\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 1 Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"exploration\": False,\n",
    "    \"custom\": True,\n",
    "    \"transfer\": False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_dir = \"data/Annotations\"\n",
    "images_dir = \"data/Images\"\n",
    "target_dir = \"data/Targets\"\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2 Dataset exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breeds_distribution(dataset, figsize=(25, 5), display_mean=True):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    sns.barplot(x=fre_df[\"Breed\"], y=fre_df[\"Population\"])\n",
    "\n",
    "    if display_mean:\n",
    "        mean = fre_df.mean(axis=0)[0]\n",
    "        plt.axhline(mean, linestyle=\"--\", linewidth=1, color=\"r\")\n",
    "\n",
    "    plt.title(\"Breeds distribution\", size=20)\n",
    "    plt.xticks(size=10, rotation=45, ha=\"right\")\n",
    "    plt.yticks(size=10)\n",
    "    plt.ylabel(\"Count\", size=16)\n",
    "\n",
    "    if display_mean:\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2.1 Breeds distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many breeds are present in the dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_subdir = os.listdir(images_dir)\n",
    "print(f\"There is {len(breed_subdir)} different dog breeds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a pandas dataset with all breeds and each of their respective population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_full: list = []\n",
    "breed: list = []\n",
    "population: list = []\n",
    "\n",
    "for sub_d in breed_subdir:\n",
    "    breed_full.append(sub_d)\n",
    "    breed.append(sub_d.split(\"-\")[1])\n",
    "    population.append(len([obs for obs in os.listdir(images_dir + \"/\" + sub_d)]))\n",
    "\n",
    "fre_df = pd.DataFrame(data={\"Breed_full\": breed_full, \"Breed\": breed, \"Population\": population})\n",
    "fre_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the breeds populations and the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"exploration\"]:\n",
    "    mean = breeds_distribution(fre_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot again bu after a sort on Population field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"exploration\"]:\n",
    "    fre_df.sort_values(by=\"Population\", inplace=True, ascending=False, axis=0)\n",
    "    mean = breeds_distribution(fre_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the top three breeds, see if they are sufficiently differents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"exploration\"]:\n",
    "\n",
    "    fix, axs = plt.subplots(3, 3, figsize=(20, 10))\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "    # Malteses\n",
    "    plt.subplot(3, 3, 1)\n",
    "    image = tf.io.read_file(\"data/Images/n02085936-Maltese_dog/n02085936_37.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 2)\n",
    "    image = tf.io.read_file(\"data/Images/n02085936-Maltese_dog/n02085936_66.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 3)\n",
    "    image = tf.io.read_file(\"data/Images/n02085936-Maltese_dog/n02085936_233.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Afghan\n",
    "    plt.subplot(3, 3, 4)\n",
    "    image = tf.io.read_file(\"data/Images/n02088094-Afghan_hound/n02088094_231.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 5)\n",
    "    image = tf.io.read_file(\"data/Images/n02088094-Afghan_hound/n02088094_251.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 6)\n",
    "    image = tf.io.read_file(\"data/Images/n02088094-Afghan_hound/n02088094_272.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Scottish deerhound\n",
    "    plt.subplot(3, 3, 7)\n",
    "    image = tf.io.read_file(\"data/Images/n02092002-Scottish_deerhound/n02092002_3.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 8)\n",
    "    image = tf.io.read_file(\"data/Images/n02092002-Scottish_deerhound/n02092002_198.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 9)\n",
    "    image = tf.io.read_file(\"data/Images/n02092002-Scottish_deerhound/n02092002_86.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the images don't have the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fre_df = fre_df.iloc[:10,:]\n",
    "fre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 3 Custom CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_dataset_directory(breeds: list, source_dir: str = \"data/Images\", target_dir: str = \"data/Targets\"):\n",
    "    if os.path.exists(target_dir):\n",
    "        shutil.rmtree(target_dir)\n",
    "    os.mkdir(target_dir)\n",
    "    for breed in breeds:\n",
    "        source = source_dir + \"/\" + breed\n",
    "        target = target_dir + \"/\" + breed\n",
    "        shutil.copytree(source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.1 Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"custom\"]:\n",
    "\n",
    "    sync_dataset_directory(fre_df[\"Breed_full\"])\n",
    "\n",
    "    ds_train_ = image_dataset_from_directory(\n",
    "        target_dir,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        image_size=[224, 224],\n",
    "        interpolation=\"nearest\",\n",
    "        batch_size=batch_size,\n",
    "        seed=0,\n",
    "        shuffle=True,\n",
    "        validation_split=0.8,\n",
    "        subset=\"training\"\n",
    "    )\n",
    "\n",
    "    ds_valid_ = image_dataset_from_directory(\n",
    "        target_dir,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        image_size=[224, 224],\n",
    "        interpolation=\"nearest\",\n",
    "        batch_size=batch_size,\n",
    "        seed=0,\n",
    "        shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\"\n",
    "    )\n",
    "\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    ds_train = (\n",
    "        ds_train_\n",
    "        .map(convert_to_float)\n",
    "        .cache()\n",
    "        .prefetch(buffer_size=AUTOTUNE)\n",
    "    )\n",
    "    ds_valid = (\n",
    "        ds_valid_\n",
    "        .map(convert_to_float)\n",
    "        .cache()\n",
    "        .prefetch(buffer_size=AUTOTUNE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.2 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"custom\"]:\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        # >>> preprocessing <<<\n",
    "\n",
    "        # >>> base <<<\n",
    "        layers.Conv2D(\n",
    "            input_shape=[224, 224, 3],\n",
    "            filters=32,\n",
    "            kernel_size=3,\n",
    "            activation=\"relu\",\n",
    "            padding=\"same\"\n",
    "            ),\n",
    "        layers.MaxPool2D(),\n",
    "        \n",
    "        # >>> head <<<\n",
    "        layers.Flatten(),\n",
    "        # layers.Dropout(rate=0.3),\n",
    "        # layers.BatchNormalization(),\n",
    "        layers.Dense(units=6, activation=\"relu\"),\n",
    "        layers.Dense(units=fre_df.shape[0], activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"custom\"]:\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"categorical_accuracy\"]\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        min_delta=0.001,\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        ds_train,\n",
    "        validation_data=ds_valid,\n",
    "        epochs=20,\n",
    "        # callbacks=[early_stopping]\n",
    "        # verbose=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.3 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"custom\"]:\n",
    "    history_frame = pd.DataFrame(history.history)\n",
    "    history_frame.loc[:, (\"loss\", \"val_loss\")].plot()\n",
    "    history_frame.loc[:, (\"categorical_accuracy\", \"val_categorical_accuracy\")].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 4 Transfer learning CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"transfer\"]:\n",
    "\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "586ad1ed5c97141e2437e681efbf1ec0adcd17d830cf5af2ca3d2819e743e158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
