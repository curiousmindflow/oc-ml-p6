{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, warnings\n",
    "import shutil\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, CSVLogger, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.xception import Xception\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "from scripts import read_saves, write_saves, record_saves\n",
    "\n",
    "def set_seed(seed=31415):\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    # os.environ['TF_CUDNN_DETERMINISTIC'] = 'true'\n",
    "    # os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "set_seed()\n",
    "\n",
    "plt.rc('figure', autolayout=True)\n",
    "plt.rc('axes', labelweight='bold', labelsize='large',\n",
    "       titleweight='bold', titlesize=18, titlepad=10)\n",
    "plt.rc('image', cmap='magma')\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "if tf.test.gpu_device_name():\n",
    "    print(f\"GPU used: {tf.test.gpu_device_name()}\")\n",
    "else:\n",
    "    print(f\"GPU not used\")\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "from tensorflow.python.client import device_lib \n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 1 Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"exploration\": False,\n",
    "    \"data_augmentation\": False,\n",
    "    \"custom\": False,\n",
    "    \"transfer\": {\n",
    "        \"vgg16\": False,\n",
    "        \"xception\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_dir = \"data/Annotations\"\n",
    "images_dir = \"data/Images\"\n",
    "target_dir = \"data/Targets\"\n",
    "batch_size = 16\n",
    "\n",
    "SAVE_PATH = \"data/saves.pkl\"\n",
    "SAVE_NB = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2 Dataset exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.0 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_float(image, label):\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breeds_distribution(dataset, figsize=(25, 5), display_mean=True):\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    sns.barplot(x=fre_df[\"Breed\"], y=fre_df[\"Population\"])\n",
    "\n",
    "    if display_mean:\n",
    "        mean = fre_df.mean(axis=0)[0]\n",
    "        plt.axhline(mean, linestyle=\"--\", linewidth=1, color=\"r\")\n",
    "\n",
    "    plt.title(\"Breeds distribution\", size=20)\n",
    "    plt.xticks(size=10, rotation=45, ha=\"right\")\n",
    "    plt.yticks(size=10)\n",
    "    plt.ylabel(\"Count\", size=16)\n",
    "\n",
    "    if display_mean:\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 2.1 Breeds distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many breeds are present in the dataset ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_subdir = os.listdir(images_dir)\n",
    "print(f\"There is {len(breed_subdir)} different dog breeds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a pandas dataset with all breeds and each of their respective population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_full: list = []\n",
    "breed: list = []\n",
    "population: list = []\n",
    "\n",
    "for sub_d in breed_subdir:\n",
    "    breed_full.append(sub_d)\n",
    "    breed.append(sub_d.split(\"-\")[1])\n",
    "    population.append(len([obs for obs in os.listdir(images_dir + \"/\" + sub_d)]))\n",
    "\n",
    "fre_df = pd.DataFrame(data={\"Breed_full\": breed_full, \"Breed\": breed, \"Population\": population})\n",
    "fre_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the breeds populations and the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"exploration\"]:\n",
    "    mean = breeds_distribution(fre_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot again bu after a sort on Population field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"exploration\"]:\n",
    "    fre_df.sort_values(by=\"Population\", inplace=True, ascending=False, axis=0)\n",
    "    mean = breeds_distribution(fre_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the top three breeds, see if they are sufficiently differents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"exploration\"]:\n",
    "\n",
    "    fix, axs = plt.subplots(3, 3, figsize=(20, 10))\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "\n",
    "    # Malteses\n",
    "    plt.subplot(3, 3, 1)\n",
    "    image = tf.io.read_file(\"data/Images/n02085936-Maltese_dog/n02085936_37.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 2)\n",
    "    image = tf.io.read_file(\"data/Images/n02085936-Maltese_dog/n02085936_66.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 3)\n",
    "    image = tf.io.read_file(\"data/Images/n02085936-Maltese_dog/n02085936_233.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Afghan\n",
    "    plt.subplot(3, 3, 4)\n",
    "    image = tf.io.read_file(\"data/Images/n02088094-Afghan_hound/n02088094_231.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 5)\n",
    "    image = tf.io.read_file(\"data/Images/n02088094-Afghan_hound/n02088094_251.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 6)\n",
    "    image = tf.io.read_file(\"data/Images/n02088094-Afghan_hound/n02088094_272.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Scottish deerhound\n",
    "    plt.subplot(3, 3, 7)\n",
    "    image = tf.io.read_file(\"data/Images/n02092002-Scottish_deerhound/n02092002_3.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 8)\n",
    "    image = tf.io.read_file(\"data/Images/n02092002-Scottish_deerhound/n02092002_198.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(3, 3, 9)\n",
    "    image = tf.io.read_file(\"data/Images/n02092002-Scottish_deerhound/n02092002_86.jpg\")\n",
    "    image = tf.io.decode_jpeg(image, channels=3)\n",
    "    img = tf.squeeze(image).numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the images don't have the same size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fre_df = fre_df.iloc[:10,:]\n",
    "fre_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 3 Dataset preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sync_dataset_directory(breeds: list, source_dir: str = \"data/Images\", target_dir: str = \"data/Targets\"):\n",
    "    if os.path.exists(target_dir):\n",
    "        shutil.rmtree(target_dir)\n",
    "    os.mkdir(target_dir)\n",
    "    for breed in breeds:\n",
    "        source = source_dir + \"/\" + breed\n",
    "        target = target_dir + \"/\" + breed\n",
    "        shutil.copytree(source, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.1 Without augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not config[\"data_augmentation\"]:\n",
    "\n",
    "    sync_dataset_directory(fre_df[\"Breed_full\"])\n",
    "\n",
    "    ds_train_ = image_dataset_from_directory(\n",
    "        target_dir,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        image_size=[224, 224],\n",
    "        interpolation=\"nearest\",\n",
    "        batch_size=batch_size,\n",
    "        seed=0,\n",
    "        shuffle=True,\n",
    "        validation_split=0.8,\n",
    "        subset=\"training\"\n",
    "    )\n",
    "\n",
    "    ds_valid_ = image_dataset_from_directory(\n",
    "        target_dir,\n",
    "        labels=\"inferred\",\n",
    "        label_mode=\"categorical\",\n",
    "        image_size=[224, 224],\n",
    "        interpolation=\"nearest\",\n",
    "        batch_size=batch_size,\n",
    "        seed=0,\n",
    "        shuffle=True,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\"\n",
    "    )\n",
    "\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    ds_train = (\n",
    "        ds_train_\n",
    "        .map(convert_to_float)\n",
    "        .cache()\n",
    "        .prefetch(buffer_size=AUTOTUNE)\n",
    "    )\n",
    "    ds_valid = (\n",
    "        ds_valid_\n",
    "        .map(convert_to_float)\n",
    "        .cache()\n",
    "        .prefetch(buffer_size=AUTOTUNE)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.2 With augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"data_augmentation\"]:\n",
    "\n",
    "    sync_dataset_directory(fre_df[\"Breed_full\"])\n",
    "\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        zca_whitening=True,\n",
    "        rotation_range=90,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        validation_split=0.2,\n",
    "        rescale=1./224\n",
    "        )\n",
    "\n",
    "    valid_datagen = ImageDataGenerator(\n",
    "        validation_split=0.2,\n",
    "        rescale=1./224\n",
    "        )\n",
    "\n",
    "    train_aug = train_datagen.flow_from_directory(\n",
    "        target_dir,\n",
    "        target_size=(224, 224),\n",
    "        subset=\"training\",\n",
    "        batch_size=16,\n",
    "        shuffle=True\n",
    "        )\n",
    "\n",
    "    val_aug = valid_datagen.flow_from_directory(\n",
    "        target_dir,\n",
    "        target_size=(224, 224),\n",
    "        subset=\"validation\",\n",
    "        batch_size=4,\n",
    "        shuffle=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 4 Custom CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.0 Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_history(history, figsize=(20, 10), metrics: str = \"categorical_accuracy\"):\n",
    "    fix, axs = plt.subplots(2, 1, figsize=figsize, sharex=True)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.title(\"Loss\")\n",
    "    sns.lineplot(data=history, x=history.index, y=\"loss\", label=\"loss\")\n",
    "    sns.lineplot(data=history, x=history.index, y=\"val_loss\", label=\"val_loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.tick_params(labelright=True)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    sns.lineplot(data=history, x=history.index, y=metrics, label=metrics)\n",
    "    sns.lineplot(data=history, x=history.index, y=\"val_\" + metrics, label=\"val_\" + metrics)\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.tick_params(labelright=True)\n",
    "    plt.legend()\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 4.1 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"custom\"]:\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        layers.InputLayer(input_shape=[224, 224, 3]),\n",
    "\n",
    "        # >>> base <<<\n",
    "        # > block 1 <\n",
    "        layers.Conv2D(\n",
    "            filters=16,\n",
    "            kernel_size=3,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            use_bias=False\n",
    "            ),\n",
    "        layers.BatchNormalization(scale=False),\n",
    "        layers.Activation(activation=\"relu\"),\n",
    "        layers.MaxPool2D(\n",
    "            pool_size=4,\n",
    "            # strides=2,\n",
    "            padding=\"same\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        # > block 1: end <\n",
    "\n",
    "        # > block 2 <\n",
    "        layers.Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=3,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            use_bias=False\n",
    "            ),\n",
    "        layers.BatchNormalization(scale=False),\n",
    "        layers.Activation(activation=\"relu\"),\n",
    "        layers.MaxPool2D(\n",
    "            pool_size=4,\n",
    "            # strides=2,\n",
    "            padding=\"same\"\n",
    "        ),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        # > block 2: end <\n",
    "\n",
    "        # > block 3 <\n",
    "        layers.Conv2D(\n",
    "            filters=64,\n",
    "            kernel_size=3,\n",
    "            strides=1,\n",
    "            padding=\"same\",\n",
    "            use_bias=False\n",
    "            ),\n",
    "        layers.BatchNormalization(scale=False),\n",
    "        layers.Activation(activation=\"relu\"),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        # > block 3: end <\n",
    "        # >>> base: end <<<\n",
    "\n",
    "        # >>> head <<<\n",
    "        # layers.Flatten(),\n",
    "\n",
    "        layers.Dense(units=128, activation=\"relu\"),\n",
    "\n",
    "        layers.Dense(units=fre_df.shape[0], activation=\"softmax\")\n",
    "        # >>> head: end <<<\n",
    "    ])\n",
    "\n",
    "    # model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"custom\"]:\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"categorical_accuracy\"]\n",
    "    )\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        './base.model',\n",
    "        monitor='val_loss',\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        mode='min',\n",
    "        save_weights_only=False,\n",
    "        period=1\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        min_delta=0.001,\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    tensorboard = TensorBoard(\n",
    "        log_dir=\"./logs\",\n",
    "        histogram_freq=0,\n",
    "        write_graph=True,\n",
    "        write_images=False\n",
    "    )\n",
    "\n",
    "    csv_logger = CSVLogger(\n",
    "        filename=\"training_csv.log\",\n",
    "        separator=\",\",\n",
    "        append=False\n",
    "    )\n",
    "\n",
    "    reduce = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=3,\n",
    "        verbose=1, \n",
    "        mode='auto'\n",
    "    )\n",
    "\n",
    "    if not config[\"data_augmentation\"]:\n",
    "        print(\"Fit without aug\")\n",
    "        history = model.fit(\n",
    "            ds_train,\n",
    "            validation_data=ds_valid,\n",
    "            epochs=50,\n",
    "            workers=8,\n",
    "            # callbacks=[early_stopping],\n",
    "            # verbose=0\n",
    "        )\n",
    "    else:\n",
    "        print(\"Fit with aug\")\n",
    "        history = model.fit_generator(\n",
    "            train_aug,\n",
    "            validation_data=val_aug,\n",
    "            epochs=50,\n",
    "            steps_per_epoch=100,\n",
    "            workers=8\n",
    "            # callbacks=[early_stopping]\n",
    "            # verbose=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 3.3 Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"custom\"]:\n",
    "\n",
    "    history_df = pd.DataFrame(data=history.history)\n",
    "    visualize_history(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves = record_saves(SAVE_PATH, SAVE_NB, history, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (key, (model_json, history)) in enumerate(saves.items()):\n",
    "#     if i == 0:\n",
    "#         visualize_history(history)\n",
    "#     else:\n",
    "#         visualize_history(history, figsize=(10, 6))\n",
    "#         # json_parsed = json.loads(model_json)\n",
    "#         # print(json.dumps(json_parsed, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tab_contents = saves.keys()\n",
    "# children = []\n",
    "\n",
    "# for i, (key, (model_json, history)) in enumerate(saves.items()):\n",
    "#     if i == 0:\n",
    "#         visualize_history(history)\n",
    "#     else:\n",
    "#         out = widgets.Output()\n",
    "#         children.append(out)\n",
    "#         with out:\n",
    "#             visualize_history(history, figsize=(10, 6))\n",
    "#             json_parsed = json.loads(model_json)\n",
    "#             print(json.dumps(json_parsed, indent=4, sort_keys=True))\n",
    "\n",
    "# tab = widgets.Tab(children=children)\n",
    "# for i, child in enumerate(children):\n",
    "#     tab.set_title(i, \"tab\"+str(i))\n",
    "\n",
    "# display(tab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 5 Transfer learning CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"transfer\"][\"vgg16\"]:\n",
    "\n",
    "    vgg16 = VGG16(\n",
    "        include_top=False,\n",
    "        input_shape=(224, 224, 3),\n",
    "        weights=\"imagenet\"\n",
    "    )\n",
    "\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"transfer\"][\"vgg16\"]:\n",
    "\n",
    "    model_vgg16 = keras.Sequential([\n",
    "        # >>> base <<<\n",
    "        vgg16,\n",
    "\n",
    "        # >>> head <<<\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "\n",
    "        layers.Dropout(rate=0.5),\n",
    "        layers.Dense(units=fre_df.shape[0], activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model_vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"transfer\"][\"vgg16\"]:\n",
    "\n",
    "    model_vgg16.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"categorical_accuracy\"]\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        min_delta=0.001,\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    if not config[\"data_augmentation\"]:\n",
    "        print(\"Fit without aug\")\n",
    "        history_vgg16 = model_vgg16.fit(\n",
    "            ds_train,\n",
    "            validation_data=ds_valid,\n",
    "            epochs=20,\n",
    "            workers=8,\n",
    "            # callbacks=[early_stopping],\n",
    "            # verbose=0\n",
    "        )\n",
    "    else:\n",
    "        print(\"Fit with aug\")\n",
    "        history_vgg16 = model_vgg16.fit_generator(\n",
    "            train_aug,\n",
    "            validation_data=val_aug,\n",
    "            epochs=20,\n",
    "            steps_per_epoch=100,\n",
    "            workers=8\n",
    "            # callbacks=[early_stopping]\n",
    "            # verbose=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"transfer\"][\"vgg16\"]:\n",
    "\n",
    "    history_vgg16_df = pd.DataFrame(data=history_vgg16.history)\n",
    "    visualize_history(history_vgg16_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 5.1.1 Result without aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/transfer_vgg16_without_aug.png\" style=\"background-color:white\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 5.1.2 Result with aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/transfer_vgg16_with_aug.png\" style=\"background-color:white\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 5.2 Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"transfer\"][\"xception\"]:\n",
    "\n",
    "    xception = Xception(\n",
    "        weights=\"imagenet\",\n",
    "        include_top=False,\n",
    "        pooling=\"avg\",\n",
    "        input_shape=(224, 224, 3)\n",
    "    )\n",
    "\n",
    "    for layer in xception.layers:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"transfer\"][\"xception\"]:\n",
    "\n",
    "    model_xception = keras.Sequential([\n",
    "        # >>> base <<<\n",
    "        xception,\n",
    "\n",
    "        # >>> head <<<\n",
    "        layers.Dense(units=128, activation=\"relu\"),\n",
    "        layers.Dropout(rate=0.2),\n",
    "        layers.Dense(units=fre_df.shape[0], activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model_xception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"transfer\"][\"xception\"]:\n",
    "\n",
    "    model_xception.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"categorical_accuracy\"]\n",
    "    )\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        min_delta=0.001,\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    if not config[\"data_augmentation\"]:\n",
    "        print(\"Fit without aug\")\n",
    "        history_xception = model_xception.fit(\n",
    "            ds_train,\n",
    "            validation_data=ds_valid,\n",
    "            epochs=20,\n",
    "            workers=8,\n",
    "            # callbacks=[early_stopping],\n",
    "            # verbose=0\n",
    "        )\n",
    "    else:\n",
    "        print(\"Fit with aug\")\n",
    "        history_xception = model_xception.fit_generator(\n",
    "            train_aug,\n",
    "            validation_data=val_aug,\n",
    "            epochs=20,\n",
    "            steps_per_epoch=100,\n",
    "            workers=8\n",
    "            # callbacks=[early_stopping]\n",
    "            # verbose=0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"transfer\"][\"xception\"]:\n",
    "\n",
    "    history_xception_df = pd.DataFrame(data=history_xception.history)\n",
    "    visualize_history(history_xception_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 5.2.1 Result without aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/transfer_xception_without_aug.png\" style=\"background-color:white\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### 5.2.2 Result with aug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"plots/transfer_xception_with_aug.png\" style=\"background-color:white\">"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "586ad1ed5c97141e2437e681efbf1ec0adcd17d830cf5af2ca3d2819e743e158"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
